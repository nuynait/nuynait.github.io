<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Finding Lane Lines - Self Driving · Tianyun Shan</title><meta name="description" content="Finding Lane Lines - Self Driving - Tianyun Shan"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/img.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://blog.jerryshan.com/atom.xml" title="Tianyun Shan"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/img.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">Finding Lane Lines - Self Driving</h1><div class="post-info">Jun 30, 2018</div><div class="post-content"><p>I joined udacity <em>”Self-Driving Nano-Degree Program”</em>. Here is my notes on the first project - detecting lane lines.</p>
<span id="more"></span>

<h1 id="Detect-Lane-Lines-On-Still-Image"><a href="#Detect-Lane-Lines-On-Still-Image" class="headerlink" title="Detect Lane Lines On Still Image"></a>Detect Lane Lines On Still Image</h1><p>The first step is detecting lane lines on a still image. Here is an example image that we use to detect the lane lines.</p>
<p><img src="20170129_141917_1227WjO.png"></p>
<h2 id="Canny-Edge-Detection"><a href="#Canny-Edge-Detection" class="headerlink" title="Canny Edge Detection"></a>Canny Edge Detection</h2><p>First read in an image and convert to grayscale.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> cv2  <span class="comment">#bringing in OpenCV libraries</span></span><br><span class="line">image = mpimg.imread(<span class="string">&#x27;exit-ramp.jpg&#x27;</span>)</span><br><span class="line">gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) <span class="comment">#grayscale conversion</span></span><br><span class="line"><span class="comment"># print out image</span></span><br><span class="line">plt.imshow(image) <span class="comment">#original</span></span><br><span class="line">plt.imshow(gray, cmap=<span class="string">&#x27;gray&#x27;</span>) <span class="comment">#grayscale image</span></span><br></pre></td></tr></table></figure>

<p>Now let&#39;s try the Canny edge detector. We are applying Canny to the image. The algorithm first detect strong edge (strong gradient) pixels above <code>high_threshold</code> and reject pixels below <code>low_threshold</code>. the ratio of <code>low_threshold</code> to <code>high_threshold</code> is <a target="_blank" rel="noopener" href="http://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html#steps">recommended to be</a> 1:2 or 1:3.</p>
<p>The course recommend we include Gaussian smoothing before running <code>Canny</code>. Gaussian smoothing is essentially a way of suppressing noise and spurious gradients by averaging (<a target="_blank" rel="noopener" href="http://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=gaussianblur#gaussianblur">Here - OpenCV Doc</a>). The <code>kernel_size</code> for Gaussian smoothing to be any <strong>odd number</strong>. A larger <code>kernel_size</code> implies averaging or smoothing over a larger area.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Do all the relevant imports</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read in the image and convert to grayscale</span></span><br><span class="line"><span class="comment"># Note: in the previous example we were reading a .jpg</span></span><br><span class="line"><span class="comment"># Here we read a .png and convert to 0,255 bytescale</span></span><br><span class="line">image = mpimg.imread(<span class="string">&#x27;exit-ramp.jpg&#x27;</span>)</span><br><span class="line">gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a kernel size for Gaussian smoothing / blurring</span></span><br><span class="line">kernel_size = <span class="number">5</span> <span class="comment"># Must be an odd number (3, 5, 7...)</span></span><br><span class="line">blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define our parameters for Canny and run it</span></span><br><span class="line">low_threshold = <span class="number">50</span></span><br><span class="line">high_threshold = <span class="number">150</span></span><br><span class="line">edges = cv2.Canny(blur_gray, low_threshold, high_threshold)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the image</span></span><br><span class="line">plt.imshow(edges, cmap=<span class="string">&#x27;Greys_r&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>More details, this <a target="_blank" rel="noopener" href="https://www.udacity.com/course/introduction-to-computer-vision--ud810">Introduction to Computer Vision</a> course on <code>udacity</code> helps.</p>
<h2 id="Hough-Transform"><a href="#Hough-Transform" class="headerlink" title="Hough Transform"></a>Hough Transform</h2><p>At this point, we have the image applied Canny edge detection. In order to detect lines, we use Hough Transform on top of the Canny image. To do this, we will use an OpenCV function called <code>HoughLinesP</code> that takes several parameters.</p>
<p>If you want to know how Hough Transform is implemented in the first place, take a look at <a target="_blank" rel="noopener" href="https://alyssaq.github.io/2014/understanding-hough-transform/">this blog</a>.</p>
<p>Here is the complete source.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read in and grayscale the image</span></span><br><span class="line"><span class="comment"># Note: in the previous example we were reading a .jpg</span></span><br><span class="line"><span class="comment"># Here we read a .png and convert to 0,255 bytescale</span></span><br><span class="line">image = mpimg.imread(<span class="string">&#x27;exit-ramp.jpg&#x27;</span>)</span><br><span class="line">gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a kernel size and apply Gaussian smoothing</span></span><br><span class="line">kernel_size = <span class="number">5</span></span><br><span class="line">blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define our parameters for Canny and apply</span></span><br><span class="line">low_threshold = <span class="number">50</span></span><br><span class="line">high_threshold = <span class="number">150</span></span><br><span class="line">edges = cv2.Canny(blur_gray, low_threshold, high_threshold)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Next we&#x27;ll create a masked edges image using cv2.fillPoly()</span></span><br><span class="line">mask = np.zeros_like(edges)   </span><br><span class="line">ignore_mask_color = <span class="number">255</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># This time we are defining a four sided polygon to mask</span></span><br><span class="line">imshape = image.shape</span><br><span class="line">vertices = np.array([[(<span class="number">0</span>,imshape[<span class="number">0</span>]),(<span class="number">450</span>, <span class="number">290</span>), (<span class="number">490</span>, <span class="number">290</span>), (imshape[<span class="number">1</span>],imshape[<span class="number">0</span>])]], dtype=np.int32)</span><br><span class="line"><span class="comment"># vertices = np.array([[(0,imshape[0]),(0, 0), (imshape[1], 0), (imshape[1],imshape[0])]], dtype=np.int32)</span></span><br><span class="line">cv2.fillPoly(mask, vertices, ignore_mask_color)</span><br><span class="line">masked_edges = cv2.bitwise_and(edges, mask)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the Hough transform parameters</span></span><br><span class="line"><span class="comment"># Make a blank the same size as our image to draw on</span></span><br><span class="line">rho = <span class="number">2</span> <span class="comment"># distance resolution in pixels of the Hough grid</span></span><br><span class="line">theta = np.pi/<span class="number">180</span> <span class="comment"># angular resolution in radians of the Hough grid</span></span><br><span class="line">threshold = <span class="number">15</span>     <span class="comment"># minimum number of votes (intersections in Hough grid cell)</span></span><br><span class="line">min_line_length = <span class="number">40</span> <span class="comment">#minimum number of pixels making up a line</span></span><br><span class="line">max_line_gap = <span class="number">20</span>    <span class="comment"># maximum gap in pixels between connectable line segments</span></span><br><span class="line">line_image = np.copy(image)*<span class="number">0</span> <span class="comment"># creating a blank to draw lines on</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run Hough on edge detected image</span></span><br><span class="line"><span class="comment"># Output &quot;lines&quot; is an array containing endpoints of detected line segments</span></span><br><span class="line">lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),</span><br><span class="line">                            min_line_length, max_line_gap)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterate over the output &quot;lines&quot; and draw lines on a blank image</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">    <span class="keyword">for</span> x1,y1,x2,y2 <span class="keyword">in</span> line:</span><br><span class="line">        cv2.line(line_image,(x1,y1),(x2,y2),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a &quot;color&quot; binary image to combine with line image</span></span><br><span class="line">color_edges = np.dstack((edges, edges, edges))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw the lines on the edge image</span></span><br><span class="line">lines_edges = cv2.addWeighted(color_edges, <span class="number">0.8</span>, line_image, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">plt.imshow(lines_edges)</span><br></pre></td></tr></table></figure>

<p>For more details on <code>HoughLinesP</code> API:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)</span><br></pre></td></tr></table></figure>

<ol>
<li> <code>edges</code> - the output image from <code>Canny</code></li>
<li> <code>rho</code> and <code>theta</code> - distance and angular resolution of our grid in Hough space. Remember that in Hough, we have a grid laid out along the ($theta, $rho) axis</li>
<li> <code>threshold</code> specifies minimum number of votes (intersections in a given grid cell).</li>
<li> <code>np.array([])</code> is just a placeholder, no need to change.</li>
<li> <code>min_line_length</code> is minimum length of a line that you will accept in the output</li>
<li> <code>max_line_gap</code> is maximum distance between segments that you will allow to be connected into a single line</li>
</ol>
<h1 id="Detect-Lane-Lines-On-Video-project"><a href="#Detect-Lane-Lines-On-Video-project" class="headerlink" title="Detect Lane Lines On Video (project)"></a>Detect Lane Lines On Video (project)</h1><p>Process on video is similar to process on still images. What we do is to consider write a pipeline process on still images and treat the video as a list of images and apply the pipe line on it. We already have learned how to detect lane lines on a still image. Here is the difficult part to what we learned. Previously we use <code>hough transform</code> to detect lines, now we need to only draw on solid line for left and right lane. that solid line should be connect to the bottom edge so we can detect where the lane starts while driving.</p>
<p><img src="20170205_133749_3137MGU.png"></p>
<p>The output should look something like above after detecting line segments, and the goal is to connect/average/extrapolate line segments to get output like below.</p>
<p><img src="20170205_134034_3137mag.png"></p>
<h2 id="Pipeline-on-Still-Image"><a href="#Pipeline-on-Still-Image" class="headerlink" title="Pipeline on Still Image"></a>Pipeline on Still Image</h2><p>For detail on how to detect lines, please see <code>Canny Edge Detection</code> and <code>Hough Transform</code>. Previously, we print lines on map using the following method.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">    <span class="keyword">for</span> x1,y1,x2,y2 <span class="keyword">in</span> line:</span><br><span class="line">        cv2.line(img, (x1, y1), (x2, y2), color, thickness)</span><br></pre></td></tr></table></figure>

<p>That method draws all the lines we can find, but now we want only two lines. One on the left and one on the right. How am I going to tweak this method and make it draw two lines left and right?</p>
<p>Here is how I did. It must not be the best plan but it is the one I use in the project. First, we can see that the slope for left line is negative and the slope for the right line is positive. (When x increase and y increase, the slope is positive).</p>
<p>So I loop all the lines and find one with positive slope and one with negative slope.</p>
<p>Now here are two ways I can do. One is to just loop though all the lines and find all the slopes, make an array of left slops and right slops put the positive and negative number into the correct array, and calculate left and right slope average. But this is not what I did. Why?</p>
<p>When I calculate the slope, I found out that some line I detected does not belongs to left or right, so when I get one sample of left and right slope I calculate if the slope is 0.1 difference to the left or right slope. If this close to neither left nor right, I ignore this line. The rest the similar, I put slope of the line I want in to left array and right array, calculate the average.</p>
<p>Note: when I was looping though the lines and calculate the slope, I also need to calculate the y-intersection points. See formula below to get all the y-intersections for the line and also calculate the average.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m &#x3D; (y_2 - y_1) &#x2F; (x_2 - x_1)</span><br><span class="line">b &#x3D; y - m * x</span><br></pre></td></tr></table></figure>
<p>From this point, I have both slope and y-interactions for left line and right line. There is one more thing we need to do. The line we draw must starts at the bottom edge of the image. However, the min points we get may not 100% starting from the edge, so we need to calculate the point value ourselves. How? $y = mx + b$, we have <code>m</code> and we have <code>b</code>, the y is the image height, so we can get x.</p>
<p>The other point will the point with the minY value. filter all the points for both left line and right line and find the minimum y-value point.</p>
<p>Below is all the codes I use to draw the line. Since I do not have too much time on this project, the code is a bit mass here. Its only for my own reference.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">leftM = <span class="number">0</span></span><br><span class="line">rightM = <span class="number">0</span></span><br><span class="line">findSample = <span class="number">0</span> <span class="comment"># find flag</span></span><br><span class="line">slopeDifference = <span class="number">0.2</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">    <span class="keyword">for</span> x1, y1, x2, y2 <span class="keyword">in</span> line:</span><br><span class="line">        <span class="keyword">for</span> newline <span class="keyword">in</span> lines:</span><br><span class="line">            <span class="keyword">for</span> a1, b1, a2, b2 <span class="keyword">in</span> newline:</span><br><span class="line">                <span class="keyword">if</span> x1 == a1 <span class="keyword">and</span> y1 == b1 <span class="keyword">and</span> x2 == a2 <span class="keyword">and</span> y2 == b2:</span><br><span class="line">                    <span class="comment"># all the same, ignore</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                m1 = ((y2-y1)/(x2-x1))</span><br><span class="line">                m2 = ((b2-b1)/(a2-a1))</span><br><span class="line">                <span class="keyword">if</span> m1 &gt; <span class="number">0</span> <span class="keyword">and</span> m2 &lt; <span class="number">0</span>:</span><br><span class="line">                    leftM = m1</span><br><span class="line">                    rightM = m2</span><br><span class="line">                    <span class="comment">#print(&quot;leftM = %f, rightM = %f&quot; %(leftM, rightM))</span></span><br><span class="line">                    findSample = <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> m1 &lt; <span class="number">0</span> <span class="keyword">and</span> m2 &gt; <span class="number">0</span>:</span><br><span class="line">                    leftM = m2</span><br><span class="line">                    rightM = m1</span><br><span class="line">                    <span class="comment">#print(&quot;leftM = %f, rightM = %f&quot; %(leftM, rightM))</span></span><br><span class="line">                    findSample = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> findSample == <span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> findSample == <span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> findSample == <span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> findSample == <span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">leftLinePoints = []</span><br><span class="line">rightLinePoints = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">    <span class="keyword">for</span> x1, y1, x2, y2 <span class="keyword">in</span> line:</span><br><span class="line">        m = ((y2-y1)/(x2-x1))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(m - rightM) &lt;= slopeDifference:</span><br><span class="line">            <span class="comment">#right line points</span></span><br><span class="line">            rightLinePoints.append((x1, y1))</span><br><span class="line">            rightLinePoints.append((x2, y2))</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">abs</span>(m - leftM) &lt;= slopeDifference:</span><br><span class="line">            <span class="comment">#left line points</span></span><br><span class="line">            leftLinePoints.append((x1, y1))</span><br><span class="line">            leftLinePoints.append((x2, y2))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># find smallest points in left</span></span><br><span class="line"><span class="comment"># get array of y points for leftPoints</span></span><br><span class="line">leftYPoints = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[<span class="number">1</span>], leftLinePoints))</span><br><span class="line">minLeftYPoints = <span class="built_in">min</span>(leftYPoints)</span><br><span class="line">maxLeftYPoints = <span class="built_in">max</span>(leftYPoints)</span><br><span class="line"></span><br><span class="line">minLeftPoints = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x[<span class="number">1</span>] == minLeftYPoints, leftLinePoints))[<span class="number">0</span>]</span><br><span class="line">maxLeftPoints = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x[<span class="number">1</span>] == maxLeftYPoints, leftLinePoints))[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># get array of y points for rightPoints</span></span><br><span class="line">rightYPoints = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[<span class="number">1</span>], rightLinePoints))</span><br><span class="line">minRightYPoints = <span class="built_in">min</span>(rightYPoints)</span><br><span class="line">maxRightYPoints = <span class="built_in">max</span>(rightYPoints)</span><br><span class="line"></span><br><span class="line">minRightPoints = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x[<span class="number">1</span>] == minRightYPoints, rightLinePoints))[<span class="number">0</span>]</span><br><span class="line">maxRightPoints = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x[<span class="number">1</span>] == maxRightYPoints, rightLinePoints))[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate final slope</span></span><br><span class="line">final_left_m = (maxLeftPoints[<span class="number">1</span>] - minLeftPoints[<span class="number">1</span>]) / (maxLeftPoints[<span class="number">0</span>] - minLeftPoints[<span class="number">0</span>])</span><br><span class="line">final_left_b = (minLeftPoints[<span class="number">1</span>] - (final_left_m * minLeftPoints[<span class="number">0</span>]))</span><br><span class="line">final_right_m = (maxRightPoints[<span class="number">1</span>] - minRightPoints[<span class="number">1</span>]) / (maxRightPoints[<span class="number">0</span>] - minRightPoints[<span class="number">0</span>])</span><br><span class="line">final_right_b = (minRightPoints[<span class="number">1</span>] - (final_right_m * minRightPoints[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">height, width, channels = image.shape</span><br><span class="line">final_left_point = (height - final_left_b) / final_left_m</span><br><span class="line">final_right_point = (height - final_right_b) / final_right_m</span><br><span class="line">cv2.line(line_image, minLeftPoints, (<span class="built_in">int</span>(final_left_point), height), line_color, <span class="number">10</span>)</span><br><span class="line">cv2.line(line_image, minRightPoints, (<span class="built_in">int</span>(final_right_point), height), line_color, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Use-Pipeline-On-Video"><a href="#Use-Pipeline-On-Video" class="headerlink" title="Use Pipeline On Video"></a>Use Pipeline On Video</h2><p>To use it on a video, we have all the sample codes provided. All we do is to wrap our pipe line into a <code>def process_image(image)</code> function and to apply this function to every frame of the video.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_image</span>(<span class="params">image</span>):</span></span><br><span class="line">    <span class="comment"># put the pipe line code here.</span></span><br><span class="line">    <span class="comment"># image is the input image</span></span><br><span class="line">    <span class="comment"># result is the output image</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">white_output = <span class="string">&#x27;xxx-output.mp4&#x27;</span> <span class="comment">#video output name</span></span><br><span class="line">clip1 = VideoFileClip(<span class="string">&#x27;xxx-input.mp4&#x27;</span>) <span class="comment">#video output name</span></span><br><span class="line">white_clip = clip1.fl_image(process_image)</span><br><span class="line">%time white_clip.write_videofile(white_output, audio=<span class="literal">False</span>) <span class="comment">#write to the output video file</span></span><br></pre></td></tr></table></figure>

<h1 id="Improvement"><a href="#Improvement" class="headerlink" title="Improvement"></a>Improvement</h1><p>How to make the algorithm more robust? Currently the algorithm only detect straight line because I am using the linear equation. So in situation when the road is not straight, this algorithm may fail. In order to make it better, instead calculating and drawing the straight line, we can draw the curve. I think drawing curve is not that as easy as drawing the line so another work round may be calculating multiple slope and drawing many lines to form a curve.</p>
<p>Above are just my thoughts on how to make improvements.</p>
</div></article></div></section><footer><div class="paginator"><a href="/2018/07/02/Github%20IO%20Pages%20Custom%20Domain/" class="prev">PREV</a><a href="/2018/04/13/Web%20Develop%20Environment%20-%20Apache%20in%20macOS%20Sierra%2010.12/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'nuynait';
var disqus_identifier = '2018/06/30/Finding Lane Lines - Self Driving/';
var disqus_title = 'Finding Lane Lines - Self Driving';
var disqus_url = 'http://blog.jerryshan.com/2018/06/30/Finding Lane Lines - Self Driving/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//nuynait.disqus.com/count.js" async></script><!-- block copyright--></footer></div><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>